import os
import glob
import warnings
import pandas as pd

from snakemake.utils import min_version

# Turn off performance warnings
warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)

# Set min version for Snakemake
min_version("7.2.1")

# Read in config
configfile: "config/config.yaml"

# When using --use-conda --use-singularity, this sets the OS used
container: "docker://continuumio/miniconda3"

# Input Paths
datadir = config['datadir']

# Configuration variables
reference_path = config['reference_path']

# Capture regions
regions = config['regions']

# Filter options
filtering = config['filtering']
hard = config['hard_filter']
vqsr = config['vqsr']

# VEP options
vep_cache_path = config['vep_cache_path']
vep_version = config['vep_version']


# Scatter options
scatter_count = config['scatter_count']
scatter_split_intervals = config['scatter_split_intervals']
haplotype_bamfiles = config['haplotype_bamfiles']

# Add resource paths to namespace
for name, path in config['references'].items():
  exec(f'{name} = os.path.join(reference_path, "{path}")')

# BWA index prefix
bwa_index = ref_bwt.rsplit(".bwt")

# Load fastq files
files = (
    pd.read_csv(config['fastqs'], sep='\t', dtype='object')
    .set_index(["sample", "pair"])
    .sort_index())

# Sample and pairs names
samples = list(files.index.levels[0])
pairs = list(files.index.levels[1])

# Ensure all samples are paired
sample_pairs = (
        files.reset_index()
        .groupby('sample')
        .pair.unique())

if not all([len(v) == 2 for v in sample_pairs]):
    raise ValueError("Workflow only supports paired-end samples")

# Output paths
fastqdir     = f"{datadir}/d00_fastq"
fastpdir     = f"{datadir}/d01_fastp"
bwadir       = f"{datadir}/d02_bwa"
markdupdir   = f"{datadir}/d03_markdups"
bqsrdir      = f"{datadir}/d04_bqsr"
haplotypedir = f"{datadir}/d05_haplotype"
filterdir    = f"{datadir}/d06_filter"
metricsdir   = f"{datadir}/d06_metrics"
vepdir       = f"{datadir}/d07_vep"
multiqcdir   = f"{datadir}/d08_multiqc"

# Set constraints for wildcards
wildcard_constraints:
    sample  = "|".join(samples),
    pair    = "|".join(pairs),
    var     = "snp|indel"

# Rules
include: "rules/fastq.smk"
include: "rules/fastp.smk"
include: "rules/bwa.smk"
include: "rules/markdups.smk"
include: "rules/bqsr.smk"
include: "rules/haplotype.smk"
include: "rules/apply_filter.smk"
include: "rules/metrics.smk"
include: "rules/vep.smk"
include: "rules/multiqc.smk"


# Main target
rule all:
    input:
        rules.run_metrics.input,
        rules.run_multiqc.input,
        rules.run_vep.input


